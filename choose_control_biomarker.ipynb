{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.vis_utils import load_biomarkers\n",
    "import h5py\n",
    "from utils.vis_utils import load_cell_meta\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import time\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rcParams[\"font.family\"] = \"sans-serif\"\n",
    "rcParams[\"font.sans-serif\"] = [\"Arial\", \"Liberation Sans\", \"DejaVu Sans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_IMAGES = 100\n",
    "NUMBER_OF_SAMPLES = 20_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomarkers=load_biomarkers()\n",
    "biomarker_names = biomarkers.Antibody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with h5py.File(\"data.h5\", \"r\") as hf:\n",
    "    vol_grp = hf[\"volumes\"]\n",
    "    data = vol_grp['data']\n",
    "    training_idx = vol_grp[\"train_idx\"][:NUMBER_OF_IMAGES]\n",
    "    \n",
    "    pixel_list = []\n",
    "    for img_idx in training_idx:\n",
    "        img_data = data[img_idx]  # shape: H x W x C\n",
    "        pixels = img_data.reshape(-1, img_data.shape[-1])  # shape: (H*W, C)\n",
    "        pixel_idxs = np.random.choice(pixels.shape[0], NUMBER_OF_SAMPLES, replace=False)\n",
    "        pixels = pixels[pixel_idxs]\n",
    "        pixel_list.append(pixels)\n",
    "    \n",
    "    all_pixels = np.vstack(pixel_list)\n",
    "    log_pixels = np.log1p(all_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = np.var(all_pixels, axis=0)\n",
    "print(\"Channel variances:\", variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matrix(data, title, filename=None):\n",
    "    pixel_corr_matrix = np.corrcoef(data, rowvar=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    sns.heatmap(\n",
    "        pixel_corr_matrix,\n",
    "        xticklabels=biomarker_names,\n",
    "        yticklabels=biomarker_names,\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": 0.5, \"label\": \"Pearson r\", \"orientation\": \"horizontal\"},\n",
    "    )\n",
    "    plt.title(title, fontsize=24, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{filename if filename else title}.pdf\")\n",
    "    plt.show()\n",
    "    return pixel_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerve_biomarkers = [\n",
    "    \"VAChT\",\n",
    "    \"MAP2\",\n",
    "    \"Sox2\",\n",
    "    \"TH\",\n",
    "    \"NCAM\",\n",
    "    \"Nestin\",\n",
    "    \"Peripherin\",\n",
    "    \"DCX\",\n",
    "    \"Neurofilament\",\n",
    "]\n",
    "def plot_peripherin_correlations(data, title, filename):\n",
    "    peripherin_idx = None\n",
    "    for i, name in enumerate(biomarker_names):\n",
    "        if 'Peripherin' in name:\n",
    "            peripherin_idx = i\n",
    "            break\n",
    "\n",
    "    if peripherin_idx is not None:\n",
    "        peripherin_correlations = data[peripherin_idx, :]\n",
    "        \n",
    "        # Remove Peripherin's self-correlation for the plot\n",
    "        plot_correlations = np.delete(peripherin_correlations, peripherin_idx)\n",
    "        plot_biomarker_names = [name for i, name in enumerate(biomarker_names) if i != peripherin_idx]\n",
    "        \n",
    "        # Sort by correlation values (largest to smallest)\n",
    "        sorted_indices = np.argsort(plot_correlations)\n",
    "        plot_correlations_sorted = plot_correlations[sorted_indices]\n",
    "        plot_biomarker_names_sorted = [plot_biomarker_names[i] for i in sorted_indices]\n",
    "        \n",
    "        colors = []\n",
    "        for name in plot_biomarker_names_sorted:\n",
    "            if name in nerve_biomarkers:\n",
    "                colors.append('#FF6B6B')  # Red for nerve biomarkers\n",
    "            else:\n",
    "                colors.append('#4ECDC4')  # Teal for other biomarkers\n",
    "\n",
    "        # Create a compact horizontal bar plot optimized for LaTeX\n",
    "        plt.figure(figsize=(6, 8))  # Reduced width and height\n",
    "        \n",
    "        bars = plt.barh(range(len(plot_biomarker_names_sorted)), plot_correlations_sorted, color=colors,\n",
    "                        alpha=0.8, edgecolor='black', linewidth=0.3)\n",
    "            \n",
    "        plt.ylabel('Biomarkers', fontsize=10, fontweight='bold')\n",
    "        plt.xlabel('Correlation with Peripherin', fontsize=10, fontweight='bold')\n",
    "        plt.title(title, fontsize=11, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Smaller font sizes and tighter spacing\n",
    "        plt.yticks(range(len(plot_biomarker_names_sorted)), plot_biomarker_names_sorted, fontsize=8)\n",
    "        plt.xticks(fontsize=9)\n",
    "        \n",
    "        # Add vertical reference lines\n",
    "        plt.axvline(x=0.05, color='gray', linestyle='--', alpha=0.5, linewidth=0.8)\n",
    "        plt.axvline(x=0.1, color='gray', linestyle='--', alpha=0.5, linewidth=0.8)\n",
    "        plt.axvline(x=0.2, color='gray', linestyle='--', alpha=0.5, linewidth=0.8)\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor='#FF6B6B', label='Nerve Biomarkers'),\n",
    "                        Patch(facecolor='#4ECDC4', label='Other Biomarkers')]\n",
    "        plt.legend(handles=legend_elements, loc='lower right', fontsize=9)\n",
    "        \n",
    "        plt.grid(axis='x', alpha=0.3, linewidth=0.6)\n",
    "        \n",
    "        # Tighter layout with smaller margins\n",
    "        plt.tight_layout(pad=1.0)\n",
    "        \n",
    "        # Save as PDF for LaTeX with high DPI and tight bounding box\n",
    "        plt.savefig(f\"plots/{filename}.pdf\", dpi=300, bbox_inches='tight', \n",
    "                   facecolor='white', edgecolor='none')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_corr = plot_corr_matrix(all_pixels, \"Pixel-level Correlation Matrix\", \"lin_pix_corr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_corr = plot_corr_matrix(log_pixels, \"Log transformed pixel level correlation matrix\", \"log_pix_corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_peripherin_correlations(pix_corr, \"Pixel-Wise peripherin correlations\", \"lin_pixel_peripherin_corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peripherin_correlations(log_corr, \"Pixel-Wise peripherin correlations (log transformed)\", \"log_pixel_peripherin_corr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_cells_per_image = 400\n",
    "all_cell_means = []\n",
    "all_cell_log_means = []\n",
    "cell_ids = []\n",
    "with h5py.File(\"data.h5\", \"r\") as hf:\n",
    "    vol_grp = hf[\"volumes\"]\n",
    "    data = vol_grp['data']  \n",
    "    training_idx = vol_grp[\"train_idx\"]\n",
    "    # N*H*W*C\n",
    "\n",
    "    case_ids = vol_grp[\"case_ids\"]\n",
    "\n",
    "    cell_mask_grp = hf[\"cell_masks\"]\n",
    "    cell_masks = cell_mask_grp[\"data\"]\n",
    "    # N*H*W\n",
    "    \n",
    "    # Get dimensions\n",
    "    _, H, W, C = data.shape\n",
    "\n",
    "    for train_idx in tqdm(range(min(len(training_idx),NUMBER_OF_IMAGES)), position=0):\n",
    "\n",
    "        img_idx = training_idx[train_idx]\n",
    "\n",
    "\n",
    "        # Get the current image slice and its cell mask\n",
    "        img_data = data[img_idx]  # Shape: H*W*C\n",
    "        img_mask = cell_masks[img_idx]  # Shape: H*W\n",
    "        case_id = case_ids[img_idx]\n",
    "        \n",
    "        # Find unique cell IDs in this image (excluding 0 for background)\n",
    "        img_cell_ids = np.unique(img_mask)\n",
    "        img_cell_ids = img_cell_ids[img_cell_ids > 0]\n",
    "        samples = np.random.choice(img_cell_ids, size=min(number_of_cells_per_image, len(img_cell_ids)), replace=False)\n",
    "\n",
    "        for i, cell_id in enumerate(samples):\n",
    "            print(f\"processing cell {i}\", end=\"\\r\")\n",
    "            # Create mask for this specific cell in this specific image\n",
    "            cell_mask = (img_mask == cell_id)  # Shape: H*W\n",
    "\n",
    "            \n",
    "            # Sum up biomarker values for this cell\n",
    "            cell_means = np.zeros(C)\n",
    "            cell_log_means = np.zeros(C)\n",
    "            for c in range(C):\n",
    "                # Apply mask to this channel and calculate mean\n",
    "                cell_pixels = img_data[:, :, c][cell_mask]\n",
    "                cell_log_pixels = np.log1p(img_data[:, :, c][cell_mask])\n",
    "                cell_means[c] = np.mean(cell_pixels) if cell_pixels.size > 0 else 0\n",
    "                cell_log_means[c] = np.mean(cell_log_pixels) if cell_log_pixels.size > 0 else 0\n",
    "            \n",
    "            all_cell_means.append(cell_means)\n",
    "            all_cell_log_means.append(cell_log_means)\n",
    "            cell_ids.append((case_id, cell_id))\n",
    "        print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_log_means = np.array(all_cell_log_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids = list(map(lambda x: (x[0].decode(), x[1]), cell_ids))\n",
    "len(cell_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try to account for cell size bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_means = np.array(all_cell_means)\n",
    "\n",
    "# Use DNA2 (index 37) as proxy for nuclear volume/total ion count\n",
    "dna2_idx = 37\n",
    "nuclear_volumes = all_cell_means[:, dna2_idx]\n",
    "\n",
    "# Avoid division by zero by adding small epsilon\n",
    "epsilon = 1e-6\n",
    "nuclear_volumes_safe = nuclear_volumes + epsilon\n",
    "\n",
    "# Normalize each cell's intensity vector by its nuclear volume\n",
    "normalized_cell_means = all_cell_means / nuclear_volumes_safe[:, np.newaxis]\n",
    "\n",
    "# Apply log transformation\n",
    "log_normalized_cell_means = np.log1p(normalized_cell_means)\n",
    "\n",
    "print(f\"Original shape: {all_cell_means.shape}\")\n",
    "print(f\"Normalized shape: {normalized_cell_means.shape}\")\n",
    "print(f\"Log-normalized shape: {log_normalized_cell_means.shape}\")\n",
    "print(f\"Nuclear volume range: {nuclear_volumes.min():.2f} - {nuclear_volumes.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only positive peripherin cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of Peripherin in biomarker_names\n",
    "peripherin_idx = None\n",
    "for i, name in enumerate(biomarker_names):\n",
    "    if 'Peripherin' in name:\n",
    "        peripherin_idx = i\n",
    "        break\n",
    "\n",
    "if peripherin_idx is not None:\n",
    "    # Get peripherin values for all cells\n",
    "    peripherin_values = all_cell_means[:, peripherin_idx]\n",
    "    \n",
    "    # Count positive values (greater than 0)\n",
    "    positive_count = np.sum(peripherin_values > 0)\n",
    "    total_count = len(peripherin_values)\n",
    "    \n",
    "    print(f\"Peripherin positive cells: {positive_count}\")\n",
    "    print(f\"Total cells: {total_count}\")\n",
    "    print(f\"Percentage positive: {positive_count/total_count*100:.2f}%\")\n",
    "    \n",
    "    # Show distribution of peripherin values\n",
    "    print(f\"Peripherin value range: {peripherin_values.min():.3f} - {peripherin_values.max():.3f}\")\n",
    "    print(f\"Mean peripherin value: {peripherin_values.mean():.3f}\")\n",
    "    print(f\"Median peripherin value: {np.median(peripherin_values):.3f}\")\n",
    "else:\n",
    "    print(\"Peripherin not found in biomarker names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_corr_matrix = plot_corr_matrix(all_cell_means, \"Cell-aggregated raw correlation matrix\", \"lin_cell_corr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nerve biomarkers\n",
    "VAChT,\n",
    "MAP2,\n",
    "Sox2,\n",
    "TH,\n",
    "NCAM,\n",
    "Peripherin,\n",
    "DCX,\n",
    "Neurofilament,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of Peripherin in biomarker_names\n",
    "peripherin_idx = None\n",
    "for i, name in enumerate(biomarker_names):\n",
    "    if 'Peripherin' in name:\n",
    "        peripherin_idx = i\n",
    "        break\n",
    "\n",
    "if peripherin_idx is not None:\n",
    "    # Extract correlations between Peripherin and all other biomarkers\n",
    "    peripherin_correlations = cell_corr_matrix[peripherin_idx, :]\n",
    "    \n",
    "    # Remove Peripherin's self-correlation for the plot\n",
    "    plot_correlations = np.delete(peripherin_correlations, peripherin_idx)\n",
    "    plot_biomarker_names = [name for i, name in enumerate(biomarker_names) if i != peripherin_idx]\n",
    "    \n",
    "    # Sort by correlation values (largest to smallest)\n",
    "    sorted_indices = np.argsort(plot_correlations)[::-1]\n",
    "    plot_correlations_sorted = plot_correlations[sorted_indices]\n",
    "    plot_biomarker_names_sorted = [plot_biomarker_names[i] for i in sorted_indices]\n",
    "    \n",
    "    # Create a bar plot with improved visual design\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    bars = plt.bar(range(len(plot_biomarker_names_sorted)), plot_correlations_sorted, \n",
    "                   alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    plt.xlabel('Biomarkers', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Correlation with Peripherin', fontsize=16, fontweight='bold')\n",
    "    plt.title('Cell-level Correlations: Peripherin vs All Other Biomarkers', fontsize=18, fontweight='bold', pad=20)\n",
    "    plt.xticks(range(len(plot_biomarker_names_sorted)), plot_biomarker_names_sorted, rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    # Add horizontal reference lines\n",
    "    plt.axhline(y=0.05, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    plt.axhline(y=0.1, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    plt.axhline(y=0.2, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3, linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save as PDF for LaTeX with high DPI\n",
    "    plt.savefig(\"plots/peripherin_correlations.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top positive and negative correlations (excluding self-correlation)\n",
    "    sorted_indices = np.argsort(peripherin_correlations)[::-1]\n",
    "    # Filter out the peripherin index from sorted results\n",
    "    filtered_indices = [i for i in sorted_indices if i != peripherin_idx]\n",
    "    \n",
    "    print(\"Top 5 positive correlations with Peripherin:\")\n",
    "    for i in filtered_indices[:5]:\n",
    "        print(f\"{biomarker_names[i]}: {peripherin_correlations[i]:.3f}\")\n",
    "    \n",
    "    print(\"\\nTop 5 negative correlations with Peripherin:\")\n",
    "    for i in filtered_indices[-5:]:\n",
    "        print(f\"{biomarker_names[i]}: {peripherin_correlations[i]:.3f}\")\n",
    "else:\n",
    "    print(\"Peripherin not found in biomarker names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr_matrix(all_cell_log_means, \"Cell-aggregated raw correlation matrix (log transformed)\", \"log_cell_corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compare with the original linear correlation matrix from cell 44\n",
    "if 'pixel_corr_matrix' in globals():\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cell_corr_matrix, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Linear Scale Correlations\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(cell_log_corr_matrix, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Log-transformed Correlations\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Cell Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data.h5\", \"r+\") as hf:\n",
    "    vol_grp = hf[\"volumes\"]\n",
    "    data = vol_grp['data']\n",
    "    training_idx = vol_grp[\"train_idx\"]\n",
    "    \n",
    "    # Get cell masks to identify empty regions\n",
    "    cell_mask_grp = hf[\"cell_masks\"]\n",
    "    cell_masks = cell_mask_grp[\"data\"]\n",
    "    \n",
    "    N, H, W = cell_masks.shape\n",
    "    \n",
    "    # Create non_cell_masks group if it doesn't exist\n",
    "    if \"non_cell_masks\" in hf:\n",
    "        del hf[\"non_cell_masks\"]\n",
    "    \n",
    "    non_cell_mask_grp = hf.create_group(\"non_cell_masks\")\n",
    "    non_cell_masks = non_cell_mask_grp.create_dataset(\"data\", shape=(N, H, W), dtype=cell_masks.dtype)\n",
    "    \n",
    "    # Process each image\n",
    "    for img_idx in tqdm(range(N), desc=\"Creating non-cell masks\"):\n",
    "        cell_mask = cell_masks[img_idx]\n",
    "        non_cell_mask = np.zeros_like(cell_mask)\n",
    "        \n",
    "        square_id = 1\n",
    "        \n",
    "        # Scan image in 5x5 grid pattern\n",
    "        for y in range(0, H-4, 5):  # Step by 5 to avoid overlap\n",
    "            for x in range(0, W-4, 5):  # Step by 5 to avoid overlap\n",
    "                # Check if entire 5x5 square has no cells (all zeros)\n",
    "                square_region = cell_mask[y:y+5, x:x+5]\n",
    "                \n",
    "                if np.all(square_region == 0):\n",
    "                    # Assign unique ID to this 5x5 square\n",
    "                    non_cell_mask[y:y+5, x:x+5] = square_id\n",
    "                    square_id += 1\n",
    "        \n",
    "        non_cell_masks[img_idx] = non_cell_mask\n",
    "        \n",
    "        if img_idx == 0:  # Print stats for first image\n",
    "            unique_ids = np.unique(non_cell_mask)\n",
    "            print(f\"Created {len(unique_ids)-1} non-cell regions in first image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_super_pixels_per_image = 400\n",
    "all_non_cell_means = []\n",
    "all_non_cell_log_means = []\n",
    "non_cell_ids = []\n",
    "with h5py.File(\"data.h5\", \"r\") as hf:\n",
    "    vol_grp = hf[\"volumes\"]\n",
    "    data = vol_grp['data']  \n",
    "    training_idx = vol_grp[\"train_idx\"]\n",
    "    # N*H*W*C\n",
    "\n",
    "    case_ids = vol_grp[\"case_ids\"]\n",
    "\n",
    "    non_cell_mask_grp = hf[\"non_cell_masks\"]\n",
    "    non_cell_masks = non_cell_mask_grp[\"data\"]\n",
    "    # N*H*W\n",
    "    \n",
    "    # Get dimensions\n",
    "    _, H, W, C = data.shape\n",
    "\n",
    "    for train_idx in tqdm(range(min(len(training_idx),NUMBER_OF_IMAGES)), position=0):\n",
    "\n",
    "        img_idx = training_idx[train_idx]\n",
    "\n",
    "\n",
    "        # Get the current image slice and its non_cell mask\n",
    "        img_data = data[img_idx]  # Shape: H*W*C\n",
    "        img_mask = non_cell_masks[img_idx]  # Shape: H*W\n",
    "        case_id = case_ids[img_idx]\n",
    "        \n",
    "        # Find unique non_cell IDs in this image (excluding 0 for background)\n",
    "        img_non_cell_ids = np.unique(img_mask)\n",
    "        img_non_cell_ids = img_non_cell_ids[img_non_cell_ids > 0]\n",
    "        samples = np.random.choice(img_non_cell_ids, size=min(number_of_super_pixels_per_image, len(img_non_cell_ids)), replace=False)\n",
    "\n",
    "        for i, non_cell_id in enumerate(samples):\n",
    "            print(f\"processing non_cell {i}\", end=\"\\r\")\n",
    "            # Create mask for this specific non_cell in this specific image\n",
    "            non_cell_mask = (img_mask == non_cell_id)  # Shape: H*W\n",
    "\n",
    "            \n",
    "            # Sum up biomarker values for this non_cell\n",
    "            non_cell_means = np.zeros(C)\n",
    "            non_cell_log_means = np.zeros(C)\n",
    "            for c in range(C):\n",
    "                # Apply mask to this channel and calculate mean\n",
    "                non_cell_pixels = img_data[:, :, c][non_cell_mask]\n",
    "                non_cell_log_pixels = np.log1p(img_data[:, :, c][non_cell_mask])\n",
    "                non_cell_means[c] = np.mean(non_cell_pixels) if non_cell_pixels.size > 0 else 0\n",
    "                non_cell_log_means[c] = np.mean(non_cell_log_pixels) if non_cell_log_pixels.size > 0 else 0\n",
    "            \n",
    "            all_non_cell_means.append(non_cell_means)\n",
    "            all_non_cell_log_means.append(non_cell_log_means)\n",
    "            non_cell_ids.append((case_id, non_cell_id))\n",
    "        print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_non_cell_means = np.array(all_non_cell_means)\n",
    "all_non_cell_log_means = np.array(all_non_cell_log_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "non_cell_corr_matrix = plot_corr_matrix(all_non_cell_means, \"non-segmented corr matrix\", \"lin_non_cell_corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "non_cell_log_corr_matrix = plot_corr_matrix(all_non_cell_log_means, \"non-segmented corr matrix (log transformed)\", \"log_non_cell_corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_non_cell_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peripherin_correlations(non_cell_corr_matrix, \"Unsegmented super-pixel correlations\", \"filtered_peripherin_correlations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_peripherin_correlations(non_cell_log_corr_matrix, \"Unsegmented super-pixel correlations(log transformed)\", \"log_filtered_peripherin_correlations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find the index of Peripherin in biomarker_names\n",
    "peripherin_idx = None\n",
    "for i, name in enumerate(biomarker_names):\n",
    "    if 'Neurofilament' in name:\n",
    "        peripherin_idx = i\n",
    "        break\n",
    "\n",
    "if peripherin_idx is not None:\n",
    "    # Get peripherin values for all non_cells\n",
    "    peripherin_values = np.array(all_non_cell_means)[:, peripherin_idx]\n",
    "    \n",
    "    # Count positive values (greater than 0)\n",
    "    positive_count = np.sum(peripherin_values > 0)\n",
    "    total_count = len(peripherin_values)\n",
    "    \n",
    "    print(f\"Peripherin positive non_cells: {positive_count}\")\n",
    "    print(f\"Total non_cells: {total_count}\")\n",
    "    print(f\"Percentage positive: {positive_count/total_count*100:.2f}%\")\n",
    "    \n",
    "    # Show distribution of peripherin values\n",
    "    print(f\"Peripherin value range: {peripherin_values.min():.3f} - {peripherin_values.max():.3f}\")\n",
    "    print(f\"Mean peripherin value: {peripherin_values.mean():.3f}\")\n",
    "    print(f\"Median peripherin value: {np.median(peripherin_values):.3f}\")\n",
    "else:\n",
    "    print(\"Peripherin not found in biomarker names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix (pixel-wise, across channels)\n",
    "peripherin_idx = 31  # Peripherin index from biomarker_names\n",
    "peripherin_values = np.array(all_non_cell_log_means)[:, peripherin_idx]\n",
    "positive_mask = peripherin_values > 0\n",
    "\n",
    "all_positive_peripherin_non_cell_means = np.array(all_non_cell_log_means)[positive_mask]\n",
    "plot_corr_matrix(all_positive_peripherin_non_cell_means, \"positive peripherine filtered means\", \"lin_pos_peripherine_filtered_corr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, p = spearmanr(all_non_cell_means, axis=0)      # rho: (40, 40) incl. 2 summary rows/cols\n",
    "spearman_corr = rho[:38, :38]    \n",
    "\n",
    "\n",
    "non_cell_rho, non_cell_p = spearmanr(all_positive_peripherin_non_cell_means, axis=0)      # rho: (40, 40) incl. 2 summary rows/cols\n",
    "non_cell_spearman_corr = non_cell_rho[:38, :38]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(22, 10))\n",
    "\n",
    "# Pixel-level MI matrix\n",
    "sns.heatmap(spearman_corr, \n",
    "            xticklabels=biomarker_names, \n",
    "            yticklabels=biomarker_names,\n",
    "            cmap=\"viridis\", annot=False, ax=axs[0])\n",
    "axs[0].set_title(\"Pairwise Spearman Correlation (cell Level)\")\n",
    "axs[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Cell-level MI matrix\n",
    "sns.heatmap(non_cell_spearman_corr, \n",
    "            xticklabels=biomarker_names, \n",
    "            yticklabels=biomarker_names,\n",
    "            cmap=\"viridis\", annot=False, ax=axs[1])\n",
    "axs[1].set_title(\"Pairwise Spearman Correlation (non Cell Means)\")\n",
    "axs[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peripherin_correlations(non_cell_spearman_corr, \"spearman corr\", \"peripherin_spearmans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Mutual Information (MI) Between Biomarkers\n",
    "\n",
    "Mutual information (MI) quantifies the dependency between two variables, capturing both linear and non-linear relationships. Here, we compute the pairwise MI between all biomarker channels using pixel-level data, and visualize the MI matrix as a heatmap. This provides an alternative perspective to correlation analysis for understanding biomarker relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_non_cell_log_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomarkers_to_investigate = list(range(38))\n",
    "\n",
    "n_mi_pixels = 10_000\n",
    "mi_pixels = all_non_cell_log_means[np.random.choice(len(all_non_cell_log_means), size=n_mi_pixels, replace=False)]\n",
    "# mi_pixels = log_pixels\n",
    "\n",
    "# Compute pairwise mutual information matrix\n",
    "C = len(biomarkers_to_investigate)\n",
    "mi_matrix = np.zeros((C, C))\n",
    "for i in tqdm(range(C), \"Outer loop\", position=0):\n",
    "    for j in tqdm(range(C), \"Inner loop\", position=1, leave=False):\n",
    "        idx1 = biomarkers_to_investigate[i]\n",
    "        idx2 = biomarkers_to_investigate[j]\n",
    "        if i == j:\n",
    "            mi_matrix[i, j] = np.nan  # MI with self is not informative\n",
    "        else:\n",
    "            # MI is not symmetric, so average MI(X|Y) and MI(Y|X)\n",
    "            mi_ij = mutual_info_regression(mi_pixels[:, [idx1]], mi_pixels[:, idx2], random_state=42)\n",
    "            mi_ji = mutual_info_regression(mi_pixels[:, [idx2]], mi_pixels[:, idx1], random_state=42)\n",
    "            mi_matrix[i, j] = 0.5 * (mi_ij[0] + mi_ji[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_matrix_no_nan = np.nan_to_num(mi_matrix)\n",
    "plot_corr_matrix(mi_matrix_no_nan, \"mutual information\",\"mutual_information\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peripherin_correlations(mi_matrix_no_nan, \"peripherin mutual info\", \"peripherin_mi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Basic Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpm(dataset, biomarkers_to_investigate):\n",
    "    # Ensure reproducibility within this function\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    C = len(biomarkers_to_investigate)\n",
    "    df_pixels = pd.DataFrame(\n",
    "        dataset[:, biomarkers_to_investigate],\n",
    "        columns=[biomarker_names[i] for i in biomarkers_to_investigate]\n",
    "    )\n",
    "    def make(reg):\n",
    "        \"\"\"Wrap regressor in X-scaler pipeline; optionally y-scaler.\"\"\"\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), ('reg', reg)])\n",
    "        return TransformedTargetRegressor(\n",
    "                    regressor=pipe,\n",
    "                    transformer=StandardScaler())\n",
    "        return pipe\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # --- Define models to try ---\n",
    "    models = {\n",
    "        \"MeanBaseline\": DummyRegressor(strategy='mean'),   \n",
    "        \"MedianBaseline\": DummyRegressor(strategy='median'),   \n",
    "        \"LinearRegression\": make(LinearRegression()),\n",
    "        \"Ridge\": make(Ridge()),\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=20, max_depth=5, random_state=42, n_jobs=-1)\n",
    "    }\n",
    "\n",
    "    # --- Predict each biomarker from all others ---\n",
    "    for target_name in tqdm(df_pixels.columns, desc=\"Targets\"):\n",
    "        X = df_pixels.drop(columns=target_name)\n",
    "        y = df_pixels[target_name]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        for model_name, model in tqdm(models.items(), desc=f\"Models for {target_name}\", leave=False):\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            nmse = mean_squared_error(y_test, y_pred)\n",
    "            results.append({\n",
    "                \"Target\": target_name,\n",
    "                \"Model\": model_name,\n",
    "                \"R2\": r2,\n",
    "                \"NMSE\": nmse\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    biomarker_meta = load_biomarkers()\n",
    "    metals_repeated = np.repeat(biomarker_meta[\"Metal\"].values, len(models))\n",
    "    results_df[\"Metal\"] = metals_repeated[:len(results_df)]\n",
    "\n",
    "    results_df['target_unique'] = results_df.groupby('Target').cumcount()//len(models) + 1\n",
    "    results_df['target_unique'] = results_df.apply(lambda x: f\"{x['Target']} {x['target_unique']}\" if (results_df['Target'] == x['Target']).sum()//len(models) > 1 else x['Target'], axis=1)\n",
    "\n",
    "    return models, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Non-Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_non_cell_log_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducibility for this analysis\n",
    "np.random.seed(42)\n",
    "\n",
    "biomarkers_to_investigate = list(range(len(biomarker_names)))  # Predict all biomarkers\n",
    "dataset = np.random.permutation(all_non_cell_log_means)\n",
    "\n",
    "filtered_models, filtered_results = bpm(dataset, biomarkers_to_investigate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_plot_df = filtered_results.melt(\n",
    "              id_vars=['target_unique', 'Model'],\n",
    "              value_vars=['R2', 'NMSE'],        # which metrics to plot\n",
    "              var_name='Metric',\n",
    "              value_name='Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette = {\n",
    "    \"MeanBaseline\": \"#AA4FC8\",  # red\n",
    "    \"LinearRegression\": \"#3773C2\",  # blue\n",
    "    \"Ridge\":\"#FF6B6B\" ,  # purple\n",
    "    \"RandomForest\": \"#F0B400\",  # orange–gold\n",
    "}\n",
    "\n",
    "# Filter out RandomForest from the plot data\n",
    "filtered_plot_df_no_median = filtered_plot_df[\n",
    "    filtered_plot_df[\"Model\"] != \"MedianBaseline\"\n",
    "]\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=filtered_plot_df_no_median,\n",
    "    kind=\"bar\",\n",
    "    x=\"target_unique\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Model\",\n",
    "    row=\"Metric\",  # one subplot for R2, one for NMSE\n",
    "    sharex=False,\n",
    "    sharey=False,  # independent y-axes\n",
    "    height=5,\n",
    "    aspect=2,\n",
    "    legend_out=False,\n",
    "    palette=custom_palette,  # Apply the custom palette\n",
    ")\n",
    "\n",
    "g.figure.suptitle(\n",
    "    \"Predictive Performance per Biomarker (filtered Level)\", y=1.05, fontsize=14\n",
    ")\n",
    "\n",
    "g.set_xticklabels(biomarker_names, rotation=90, ha=\"right\", fontsize=8)\n",
    "# 4 ─ add a bit of breathing room below the labels\n",
    "g.figure.subplots_adjust(bottom=0.25, hspace=0.35)\n",
    "g.axes[0][0].set_ylabel(\"R\\u00b2\")  # top panel\n",
    "g.axes[1][0].set_ylabel(\"nMSE\")  # bottom panel\n",
    "g.set_titles(\"{row_name}\")  # row titles: R2 / NMSE\n",
    "\n",
    "plt.savefig(\"plots/bnp_performance.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for R2 only and exclude MedianBaseline\n",
    "r2_data = filtered_results[(filtered_results[\"Model\"] != \"MedianBaseline\")].copy()\n",
    "\n",
    "# Create horizontal grouped bar plot optimized for LaTeX\n",
    "fig, ax = plt.subplots(figsize=(10, 12))  # Taller for horizontal layout\n",
    "\n",
    "# Get unique biomarkers and models\n",
    "biomarkers = r2_data[\"target_unique\"].unique()\n",
    "models = [\"MeanBaseline\", \"LinearRegression\", \"Ridge\", \"RandomForest\"]\n",
    "models_filtered = [m for m in models if m in r2_data[\"Model\"].unique()]\n",
    "\n",
    "# Sort biomarkers by best RandomForest performance for better visual hierarchy\n",
    "rf_scores = {}\n",
    "for bio in biomarkers:\n",
    "    rf_score = r2_data[\n",
    "        (r2_data[\"target_unique\"] == bio) & (r2_data[\"Model\"] == \"RandomForest\")\n",
    "    ][\"R2\"].iloc[0]\n",
    "    rf_scores[bio] = rf_score\n",
    "\n",
    "biomarkers_sorted = sorted(\n",
    "    biomarkers, key=lambda x: rf_scores[x], reverse=False\n",
    ")  # Changed to reverse=False for increasing order\n",
    "\n",
    "# Set up bar positions with optimal spacing\n",
    "y_pos = np.arange(len(biomarkers_sorted))\n",
    "bar_height = 0.18  # Bar height for horizontal bars\n",
    "offset = np.linspace(-1.5 * bar_height, 1.5 * bar_height, len(models_filtered))\n",
    "\n",
    "# Color palette for models\n",
    "model_colors = {\n",
    "    \"MeanBaseline\": \"#8B949E\",  # Gray for baseline\n",
    "    \"LinearRegression\": \"#1F77B4\",  # Blue\n",
    "    \"Ridge\": \"#FF7F0E\",  # Orange\n",
    "    \"RandomForest\": \"#2CA02C\",  # Green for best performer\n",
    "}\n",
    "\n",
    "# Create horizontal bars for each model\n",
    "for i, model in enumerate(models_filtered):\n",
    "    model_data = r2_data[r2_data[\"Model\"] == model]\n",
    "    scores = [\n",
    "        model_data[model_data[\"target_unique\"] == bio][\"R2\"].iloc[0]\n",
    "        for bio in biomarkers_sorted\n",
    "    ]\n",
    "\n",
    "    # Add error handling for missing data\n",
    "    scores = [max(0, score) for score in scores]  # Ensure no negative values\n",
    "\n",
    "    # Color-code bars based on whether biomarker is nerve-related\n",
    "    bar_colors = []\n",
    "    for bio in biomarkers_sorted:\n",
    "        if bio in nerve_biomarkers:\n",
    "            # Use darker/saturated version of model color for nerve biomarkers\n",
    "            base_color = model_colors[model]\n",
    "            if model == \"RandomForest\":\n",
    "                bar_colors.append(\"#1A7A1A\")  # Darker green\n",
    "            elif model == \"Ridge\":\n",
    "                bar_colors.append(\"#CC5500\")  # Darker orange\n",
    "            elif model == \"LinearRegression\":\n",
    "                bar_colors.append(\"#0F4C75\")  # Darker blue\n",
    "            else:\n",
    "                bar_colors.append(\"#5C6268\")  # Darker gray\n",
    "        else:\n",
    "            bar_colors.append(model_colors[model])\n",
    "\n",
    "    bars = ax.barh(\n",
    "        y_pos + offset[i],\n",
    "        scores,\n",
    "        bar_height,\n",
    "        color=bar_colors,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "# Add model labels to legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = []\n",
    "for model in models_filtered:\n",
    "    legend_elements.append(Patch(facecolor=model_colors[model], label=model))\n",
    "\n",
    "# Add nerve biomarker indicator to legend\n",
    "legend_elements.append(\n",
    "    Patch(facecolor=\"#000000\", label=\"Nerve Biomarkers (darker shades)\")\n",
    ")\n",
    "\n",
    "# Customize plot for LaTeX\n",
    "ax.set_ylabel(\n",
    "    \"Target Biomarkers (sorted by Random Forest performance)\",\n",
    "    fontsize=11,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xlabel(\"R² Score\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(\n",
    "    \"Cross-Validation Performance: Predicting Each Biomarker from Others\",\n",
    "    fontsize=11,\n",
    "    fontweight=\"bold\",\n",
    "    pad=15,\n",
    ")\n",
    "\n",
    "# Position y-ticks with nerve biomarkers highlighted\n",
    "tick_labels = []\n",
    "for bio in biomarkers_sorted:\n",
    "    if bio in nerve_biomarkers:\n",
    "        tick_labels.append(f\"$\\\\mathbf{{{bio}}}$\")  # Bold for nerve biomarkers\n",
    "    else:\n",
    "        tick_labels.append(bio)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(tick_labels, fontsize=10)\n",
    "ax.tick_params(axis=\"x\", labelsize=9)\n",
    "\n",
    "# Enhanced legend with better positioning\n",
    "ax.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"lower right\",\n",
    "    fontsize=10,\n",
    "    title_fontsize=11,\n",
    "    title=\"Legend\",\n",
    "    frameon=True,\n",
    "    fancybox=False,\n",
    "    shadow=False,\n",
    ")\n",
    "\n",
    "# Subtle grid only on x-axis\n",
    "ax.grid(axis=\"x\", alpha=0.3, linewidth=0.5, linestyle=\"-\")\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Set x-axis limits with some headroom\n",
    "max_score = max(\n",
    "    [max(r2_data[r2_data[\"Model\"] == model][\"R2\"]) for model in models_filtered]\n",
    ")\n",
    "ax.set_xlim(0, min(1.0, max_score * 1.15))  # Cap at 1.0 since R² shouldn't exceed 1\n",
    "\n",
    "# Tight layout optimized for LaTeX\n",
    "plt.tight_layout(pad=1.0)\n",
    "\n",
    "# Save with high quality for LaTeX\n",
    "plt.savefig(\n",
    "    \"plots/grouped_r2_performance_horizontal.pdf\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    "    edgecolor=\"none\",\n",
    "    format=\"pdf\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics including nerve biomarkers\n",
    "nerve_biomarkers_in_data = [bio for bio in biomarkers_sorted if bio in nerve_biomarkers]\n",
    "other_biomarkers_in_data = [\n",
    "    bio for bio in biomarkers_sorted if bio not in nerve_biomarkers\n",
    "]\n",
    "\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(\n",
    "    f\"Best performing target (RandomForest): {biomarkers_sorted[-1]} (R² = {rf_scores[biomarkers_sorted[-1]]:.3f})\"\n",
    ")  # Changed to [-1] for last element\n",
    "print(\n",
    "    f\"Worst performing target (RandomForest): {biomarkers_sorted[0]} (R² = {rf_scores[biomarkers_sorted[0]]:.3f})\"\n",
    ")  # Changed to [0] for first element\n",
    "print(\n",
    "    f\"Number of biomarkers with R² > 0.5: {sum(1 for score in rf_scores.values() if score > 0.5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of biomarkers with R² > 0.3: {sum(1 for score in rf_scores.values() if score > 0.3)}\"\n",
    ")\n",
    "print(f\"\\nNerve biomarkers performance:\")\n",
    "for bio in nerve_biomarkers_in_data:\n",
    "    print(f\"  {bio}: R² = {rf_scores[bio]:.3f}\")\n",
    "print(\n",
    "    f\"Average R² for nerve biomarkers: {np.mean([rf_scores[bio] for bio in nerve_biomarkers_in_data]):.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Average R² for other biomarkers: {np.mean([rf_scores[bio] for bio in other_biomarkers_in_data]):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "def plot_top_correlations_grid(correlation_matrices, titles, filename=\"top_correlations_grid\", top_n=5):\n",
    "    \"\"\"\n",
    "    Create a grid of bar plots showing top N correlations with Peripherin for different correlation matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    correlation_matrices: list of correlation matrices\n",
    "    titles: list of titles for each subplot\n",
    "    filename: base filename for saving the plot\n",
    "    top_n: number of top correlations to show (default: 5)\n",
    "    \"\"\"\n",
    "    # Find the index of Peripherin in biomarker_names\n",
    "    peripherin_idx = None\n",
    "    for i, name in enumerate(biomarker_names):\n",
    "        if 'Peripherin' in name:\n",
    "            peripherin_idx = i\n",
    "            break\n",
    "    \n",
    "    if peripherin_idx is None:\n",
    "        print(\"Peripherin not found in biomarker names\")\n",
    "        return\n",
    "    \n",
    "    n_plots = len(correlation_matrices)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_plots + 1) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4*n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (corr_matrix, title) in enumerate(zip(correlation_matrices, titles)):\n",
    "        row = idx // n_cols\n",
    "        col = idx % n_cols\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Extract correlations between Peripherin and all other biomarkers\n",
    "        peripherin_correlations = corr_matrix[peripherin_idx, :]\n",
    "        \n",
    "        # Remove Peripherin's self-correlation\n",
    "        plot_correlations = np.delete(peripherin_correlations, peripherin_idx)\n",
    "        plot_biomarker_names = [name for i, name in enumerate(biomarker_names) if i != peripherin_idx]\n",
    "        \n",
    "        # Get top N correlations\n",
    "        top_indices = np.argsort(plot_correlations)[-top_n:][::-1]  # Top N, highest first\n",
    "        top_correlations = plot_correlations[top_indices]\n",
    "        top_names = [plot_biomarker_names[i] for i in top_indices]\n",
    "        \n",
    "        # Color based on nerve biomarkers\n",
    "        colors = []\n",
    "        for name in top_names:\n",
    "            if name in nerve_biomarkers:\n",
    "                colors.append('#FF6B6B')  # Red for nerve biomarkers\n",
    "            else:\n",
    "                colors.append('#4ECDC4')  # Teal for other biomarkers\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = ax.bar(range(len(top_names)), top_correlations, color=colors, \n",
    "                     alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, fontweight='bold', pad=10)\n",
    "        ax.set_ylabel('Score with peripherin', fontsize=12)\n",
    "        ax.set_xticks(range(len(top_names)))\n",
    "        ax.set_xticklabels(top_names, rotation=45, ha='right', fontsize=12)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, top_correlations):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        ax.grid(axis='y', alpha=0.3, linewidth=0.5)\n",
    "        ax.set_ylim(0, max(top_correlations) * 1.15)\n",
    "    \n",
    "    # Hide empty subplots if odd number of plots\n",
    "    if n_plots % 2 == 1:\n",
    "        axes[-1, -1].set_visible(False)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#FF6B6B', label='Nerve Biomarkers'),\n",
    "        Patch(facecolor='#4ECDC4', label='Other Biomarkers')\n",
    "    ]\n",
    "    fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{filename}.pdf\", dpi=300, bbox_inches='tight', \n",
    "               facecolor='white', edgecolor='none')\n",
    "    plt.show()\n",
    "\n",
    "# Prepare the correlation matrices and titles\n",
    "correlation_matrices = [\n",
    "    pix_corr,\n",
    "    log_corr, \n",
    "    non_cell_corr_matrix,\n",
    "    non_cell_log_corr_matrix,\n",
    "    non_cell_spearman_corr,\n",
    "    mi_matrix_no_nan\n",
    "]\n",
    "\n",
    "titles = [\n",
    "    \"Pixel-wise correlations (Linear)\",\n",
    "    \"Pixel-wise correlations (Log Transformed)\",\n",
    "    \"Non-segmented correlations (Linear)\",\n",
    "    \"Non-segmented correlations (Log Transformed)\",\n",
    "    \"Non-segmented Spearman (Log Transformed)\",\n",
    "    \"Non-segmented Mutual information (Log Transformed)\"\n",
    "]\n",
    "\n",
    "# Example usage - you can now specify different values for top_n\n",
    "plot_top_correlations_grid(correlation_matrices, titles, \"peripherin_top10_grid\", top_n=10)\n",
    "# plot_top_correlations_grid(correlation_matrices, titles, \"peripherin_top10_grid\", top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for nerve biomarkers and specific models\n",
    "nerve_data = r2_data[\n",
    "    (r2_data[\"target_unique\"].isin(nerve_biomarkers)) & \n",
    "    (r2_data[\"Model\"].isin([\"Ridge\", \"RandomForest\"]))\n",
    "].copy()\n",
    "\n",
    "# Create comparison plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Get unique nerve biomarkers in the data\n",
    "nerve_biomarkers_in_filtered = [bio for bio in nerve_biomarkers if bio in nerve_data[\"target_unique\"].unique()]\n",
    "\n",
    "# Set up positions for grouped bars\n",
    "x_pos = np.arange(len(nerve_biomarkers_in_filtered))\n",
    "width = 0.35\n",
    "\n",
    "# Get Ridge and RandomForest scores for each nerve biomarker\n",
    "ridge_scores = []\n",
    "rf_scores = []\n",
    "\n",
    "for bio in nerve_biomarkers_in_filtered:\n",
    "    ridge_score = nerve_data[\n",
    "        (nerve_data[\"target_unique\"] == bio) & (nerve_data[\"Model\"] == \"Ridge\")\n",
    "    ][\"R2\"].iloc[0]\n",
    "    rf_score = nerve_data[\n",
    "        (nerve_data[\"target_unique\"] == bio) & (nerve_data[\"Model\"] == \"RandomForest\")\n",
    "    ][\"R2\"].iloc[0]\n",
    "    \n",
    "    ridge_scores.append(ridge_score)\n",
    "    rf_scores.append(rf_score)\n",
    "\n",
    "# Create grouped bar plot\n",
    "bars1 = ax.bar(x_pos - width/2, ridge_scores, width, label='Ridge', \n",
    "               color='#FF7F0E', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "bars2 = ax.bar(x_pos + width/2, rf_scores, width, label='RandomForest', \n",
    "               color='#2CA02C', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars1, ridge_scores):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "           f'{score:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "for bar, score in zip(bars2, rf_scores):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "           f'{score:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Nerve Biomarkers', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('R² Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Performance Comparison: Ridge vs Random Forest\\nfor Nerve-Related Biomarkers', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(nerve_biomarkers_in_filtered, rotation=45, ha='right', fontsize=11)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper left', fontsize=12, title='Model', title_fontsize=12)\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.grid(axis='y', alpha=0.3, linewidth=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0, max(max(ridge_scores), max(rf_scores)) * 1.15)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"plots/nerve_biomarkers_model_comparison.pdf\", dpi=300, bbox_inches='tight', \n",
    "           facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "\n",
    "# Print comparison statistics\n",
    "print(\"Nerve Biomarkers Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "for i, bio in enumerate(nerve_biomarkers_in_filtered):\n",
    "    ridge_score = ridge_scores[i]\n",
    "    rf_score = rf_scores[i]\n",
    "    improvement = rf_score - ridge_score\n",
    "    print(f\"{bio:15}: Ridge={ridge_score:.3f}, RF={rf_score:.3f}, Improvement={improvement:+.3f}\")\n",
    "\n",
    "print(f\"\\nAverage Ridge R²: {np.mean(ridge_scores):.3f}\")\n",
    "print(f\"Average RandomForest R²: {np.mean(rf_scores):.3f}\")\n",
    "print(f\"Average Improvement: {np.mean(rf_scores) - np.mean(ridge_scores):+.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
