{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.constants import DATA_DIR\n",
    "\n",
    "from pathlib import Path\n",
    "import json, h5py, numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from models.unet import UNet\n",
    "from utils.train_utils import get_device\n",
    "from utils.vis_utils import load_patient_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa997e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = Path(\"\")\n",
    "META_PATH = Path(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a57ea",
   "metadata": {},
   "source": [
    "# Model Instantiation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "meta = json.loads(META_PATH.read_text())\n",
    "\n",
    "if isinstance(meta.get(\"input_channels_used\"), list) and meta[\"input_channels_used\"]:\n",
    "    in_ch = len(meta[\"input_channels_used\"])\n",
    "else:\n",
    "    in_ch = int(meta.get(\"in_channels\", 37))\n",
    "\n",
    "model = UNet(\n",
    "    in_channels=in_ch,\n",
    "    out_channels=meta.get(\"out_channels\", 1),\n",
    "    depth=meta.get(\"depth\", 5),\n",
    "    bilinear=meta.get(\"bilinear\", True),\n",
    "    dropout_p=meta.get(\"dropout_p\", 0.1),\n",
    ")\n",
    "\n",
    "state = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "try:\n",
    "    model.load_state_dict(state, strict=True)\n",
    "except RuntimeError as e:\n",
    "    print(f\"[warn] non-strict load due to: {e}\")\n",
    "    model.load_state_dict(state, strict=False)\n",
    "\n",
    "model.eval().to(DEVICE)\n",
    "\n",
    "print(f\"Model ready on {DEVICE}: UNet(depth={meta.get('depth',5)}, in_ch={in_ch})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d33060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_patient_metadata()\n",
    "df\n",
    "patient_meta = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf903a6d",
   "metadata": {},
   "source": [
    "# Select Test Cases Near the Median number of nervesegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import h5py, numpy as np, pandas as pd\n",
    "\n",
    "H5_PATH = Path(\"data.h5\")  # update if needed\n",
    "\n",
    "with h5py.File(H5_PATH, \"r\") as hf:\n",
    "    case_ids = [cid.decode(\"utf-8\") for cid in hf[\"volumes\"][\"case_ids\"][:]]\n",
    "    test_idx = hf[\"volumes\"][\"test_idx\"][:]\n",
    "\n",
    "test_cases = {case_ids[i] for i in test_idx}\n",
    "\n",
    "df_test = patient_meta.copy()\n",
    "df_test[\"TMA_CASE\"] = df_test[\"TMA_CASE\"].astype(str)\n",
    "df_test = df_test[df_test[\"TMA_CASE\"].isin(test_cases)].copy()\n",
    "df_test = df_test[df_test[\"nervesegments\"].notna()]\n",
    "\n",
    "assert len(df_test) >= 3, \"Fewer than 3 test rows available.\"\n",
    "\n",
    "med = float(np.median(df_test[\"nervesegments\"].values))\n",
    "df_test[\"dist_to_median\"] = (df_test[\"nervesegments\"] - med).abs()\n",
    "\n",
    "df_test_sorted = df_test.sort_values(\n",
    "    by=[\"dist_to_median\", \"nervesegments\", \"TMA_CASE\"],\n",
    "    ascending=[True, True, True],\n",
    ")\n",
    "\n",
    "selected_df = df_test_sorted.head(3).drop(columns=[\"dist_to_median\"]).reset_index(drop=True)\n",
    "selected_cases = selected_df[\"TMA_CASE\"].tolist()\n",
    "\n",
    "print(f\"Test rows: {len(df_test)} | median(nervesegments) = {med:.3f}\")\n",
    "print(\"Selected CASE IDs:\", selected_cases)\n",
    "\n",
    "selected_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503b728",
   "metadata": {},
   "source": [
    "# Select Test Cases with High Nerve Segment Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55144c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py, numpy as np, pandas as pd\n",
    "\n",
    "H5_PATH = Path(\"data.h5\")  \n",
    "\n",
    "with h5py.File(H5_PATH, \"r\") as hf:\n",
    "    case_ids = [cid.decode(\"utf-8\") for cid in hf[\"volumes\"][\"case_ids\"][:]]\n",
    "    test_idx = hf[\"volumes\"][\"test_idx\"][:]\n",
    "test_cases = {case_ids[i] for i in test_idx}\n",
    "\n",
    "df_test = df.copy()\n",
    "df_test[\"TMA_CASE\"] = df_test[\"TMA_CASE\"].astype(str)\n",
    "df_test = df_test[df_test[\"TMA_CASE\"].isin(test_cases)].copy()\n",
    "df_test[\"nervesegments\"] = pd.to_numeric(df_test[\"nervesegments\"], errors=\"coerce\")\n",
    "df_test = df_test.dropna(subset=[\"nervesegments\"])\n",
    "\n",
    "assert len(df_test) >= 3, \"Fewer than 3 test rows available.\"\n",
    "\n",
    "p90 = float(df_test[\"nervesegments\"].quantile(0.90))\n",
    "candidates = df_test[df_test[\"nervesegments\"] >= p90].copy()\n",
    "\n",
    "sort_keys = [\"nervesegments\", \"TMA_CASE\"]\n",
    "candidates = candidates.sort_values(by=sort_keys, ascending=[False, True])\n",
    "\n",
    "if len(candidates) < 3:\n",
    "    candidates = df_test.sort_values(by=sort_keys, ascending=[False, True]).head(3)\n",
    "else:\n",
    "    candidates = candidates.head(3)\n",
    "\n",
    "selected_df = candidates.reset_index(drop=True)\n",
    "selected_cases = selected_df[\"TMA_CASE\"].tolist()\n",
    "\n",
    "print(f\"Test rows: {len(df_test)} | 90th pct = {p90:.3f}\")\n",
    "print(\"Selected CASE IDs (high-nerve):\", selected_cases)\n",
    "\n",
    "selected_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b526d",
   "metadata": {},
   "source": [
    "# Extract and Prepare Raw Volumes for Selected Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "H5_PATH = Path(\"data.h5\")  \n",
    "\n",
    "assert 'selected_cases' in globals(), \"selected_cases not defined. Run the previous cell first.\"\n",
    "assert len(selected_cases) >= 3, \"Need at least 3 case IDs.\"\n",
    "\n",
    "with h5py.File(H5_PATH, \"r\") as hf:\n",
    "    case_ids_raw = hf[\"volumes\"][\"case_ids\"][:]\n",
    "    try:\n",
    "        case_ids = [cid.decode(\"utf-8\") for cid in case_ids_raw]\n",
    "    except AttributeError:\n",
    "        case_ids = [str(cid) for cid in case_ids_raw]\n",
    "    case_to_idx = {cid: i for i, cid in enumerate(case_ids)}\n",
    "\n",
    "    data_ds = hf[\"volumes\"][\"data\"]  # shape: (N, H, W, C)\n",
    "\n",
    "    raw_volumes = []\n",
    "    for cid in selected_cases[:3]:\n",
    "        idx = case_to_idx.get(cid)\n",
    "        assert idx is not None, f\"Case ID not found in HDF5: {cid}\"\n",
    "        vol = data_ds[idx]            # (H, W, C) NumPy array (copied from HDF5)\n",
    "        raw_volumes.append(vol)\n",
    "\n",
    "# sanity check\n",
    "for cid, vol in zip(selected_cases[:3], raw_volumes):\n",
    "    print(f\"{cid}: shape={vol.shape}, dtype={vol.dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27693ed1",
   "metadata": {},
   "source": [
    "# Prepare Peripherin and Model Input Crops from Raw Volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "PERIPHERIN_CHANNEL = 31\n",
    "DROP_CHANNELS = [14, 31]\n",
    "\n",
    "assert 'raw_volumes' in globals(), \"`raw_volumes` not found. Run the previous cell first.\"\n",
    "assert 'selected_cases' in globals(), \"`selected_cases` not found.\"\n",
    "assert len(raw_volumes) >= 3, \"Need at least 3 volumes in `raw_volumes`.\"\n",
    "\n",
    "prph_crops = []       # list of (H-2, W-2) peripherin arrays\n",
    "input_crops = []      # list of (H-2, W-2, C-2) arrays with ch 14 and 31 removed\n",
    "\n",
    "for vol in raw_volumes[:3]:\n",
    "    assert vol.ndim == 3, f\"Expected (H, W, C), got shape {vol.shape}\"\n",
    "    H, W, C = vol.shape\n",
    "    assert PERIPHERIN_CHANNEL < C, f\"PERIPHERIN_CHANNEL={PERIPHERIN_CHANNEL} out of range for C={C}\"\n",
    "    assert all(ch < C for ch in DROP_CHANNELS), f\"DROP_CHANNELS out of range for C={C}\"\n",
    "\n",
    "    vol_c = vol[1:H-1, 1:W-1, :]\n",
    "\n",
    "    prph_crops.append(vol_c[:, :, PERIPHERIN_CHANNEL].astype(np.float32).copy())\n",
    "\n",
    "    keep = [i for i in range(C) if i not in DROP_CHANNELS]\n",
    "    input_crops.append(vol_c[:, :, keep].astype(np.float32).copy())\n",
    "\n",
    "for cid, prph_arr, inp_arr in zip(selected_cases[:3], prph_crops, input_crops):\n",
    "    print(f\"{cid}: peripherin {prph_arr.shape}, inputs {inp_arr.shape} (dropped {DROP_CHANNELS})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f45df2",
   "metadata": {},
   "source": [
    "# Run Model Inference and Generate Logit Maps for Selected Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d658bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, torch, h5py\n",
    "from pathlib import Path\n",
    "\n",
    "assert 'model' in globals(), \"Run your model-instantiation cell first.\"\n",
    "assert 'input_crops' in globals() and len(input_crops) >= 3, \"Need 3 crops in `input_crops`.\"\n",
    "\n",
    "H5_PATH = Path(\"data.h5\")\n",
    "DROP_CHANNELS = [14, 31]\n",
    "TOTAL_CHANNELS = 38\n",
    "keep = [i for i in range(TOTAL_CHANNELS) if i not in DROP_CHANNELS]  # ascending kept-channel order\n",
    "\n",
    "# Load normalization stats for the kept channels\n",
    "with h5py.File(H5_PATH, \"r\") as hf:\n",
    "    means = hf[\"statistics\"][\"means\"][:][keep].astype(np.float32)\n",
    "    stds  = hf[\"statistics\"][\"stds\"][:][keep].astype(np.float32)\n",
    "\n",
    "logit_maps = []\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "for arr in input_crops[:3]:           # each arr: (H, W, C_kept)\n",
    "    x = (arr - means.reshape(1,1,-1)) / (stds.reshape(1,1,-1) + 1e-8)\n",
    "    xb = torch.from_numpy(np.transpose(x.astype(np.float32), (2,0,1))).unsqueeze(0).to(device)\n",
    "    print(\"predicting:\")\n",
    "    with torch.inference_mode():\n",
    "        logits = model(xb)[0, 0].cpu().numpy().astype(np.float32)  # (H, W)\n",
    "    print(\"done:\")\n",
    "    logit_maps.append(logits)\n",
    "\n",
    "print(\"Logit map shapes:\", [m.shape for m in logit_maps])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d92bd",
   "metadata": {},
   "source": [
    "# Visualize Peripherin Channel and Model Predictions for Selected Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd69250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert 'META_PATH' in globals(), \"META_PATH not set (from model cell).\"\n",
    "assert 'selected_cases' in globals() and len(selected_cases) >= 3, \"Need 3 case IDs in `selected_cases`.\"\n",
    "assert 'prph_crops' in globals() and len(prph_crops) >= 3, \"`prph_crops` missing or too small.\"\n",
    "assert 'logit_maps' in globals() and len(logit_maps) >= 3, \"`logit_maps` missing or too small.\"\n",
    "\n",
    "thr = 0.99995\n",
    "print(f\"Using best validation threshold: {thr:.3f}\")\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "run_through = list(zip(selected_cases[:3], prph_crops[:3], logit_maps[:3]))\n",
    "chosen = run_through[2]\n",
    "for cid, prph, logits in run_through[2:]:\n",
    "    probs = sigmoid(logits)\n",
    "\n",
    "    pred_bin = (probs >= thr).astype(np.uint8)\n",
    "\n",
    "    vmax = np.percentile(prph, 99.5)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n",
    "    ax0, ax1 = axes\n",
    "\n",
    "    ax0.imshow(prph, cmap=\"gray\", vmin=0, vmax=vmax)\n",
    "    ax0.set_title(f\"Peripherin (raw)\")\n",
    "    ax0.axis(\"off\")\n",
    "\n",
    "    ax1.imshow(pred_bin, vmin=0, vmax=1)\n",
    "    ax1.set_title(f\"Model ≥ {thr:.2f} (binary)\")\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_prph_and_predictions_grid(\n",
    "    prph, logits, *,\n",
    "    thresholds=None,\n",
    "    intervals=None,\n",
    "    case_id=None,\n",
    "    prph_binary=False,\n",
    "    prph_eps=None,\n",
    "    origin=\"upper\"\n",
    "):\n",
    "    \"\"\"\n",
    "    prph:   (H, W) float array  — raw peripherin channel\n",
    "    logits: (H, W) float array  — model logits (before sigmoid)\n",
    "\n",
    "    Provide exactly one of:\n",
    "      - thresholds: list/tuple of 3 floats, each used as [t, 1.0]\n",
    "      - intervals:  list of 3 (low, high) tuples, with 0<=low<high<=1\n",
    "\n",
    "    prph_binary: if True, display PRPH as (prph > eps); else show raw grayscale.\n",
    "    prph_eps:    optional epsilon for binarization (default: dtype epsilon).\n",
    "    origin:      passed to imshow; 'upper' means y increases downward.\n",
    "    \"\"\"\n",
    "    assert (thresholds is None) ^ (intervals is None), \"Provide thresholds OR intervals (not both).\"\n",
    "\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "    if intervals is None:\n",
    "        assert len(thresholds) == 3, \"Need exactly 3 thresholds.\"\n",
    "        intervals = [(float(t), 1.0) for t in thresholds]\n",
    "    else:\n",
    "        assert len(intervals) == 3, \"Need exactly 3 intervals.\"\n",
    "        intervals = [(float(lo), float(hi)) for (lo, hi) in intervals]\n",
    "\n",
    "    masks, labels = [], []\n",
    "    for (lo, hi) in intervals:\n",
    "        assert 0.0 <= lo < hi <= 1.0, f\"Bad interval: {(lo,hi)}\"\n",
    "        m = (probs >= lo) & (probs <= hi)\n",
    "        masks.append(m.astype(np.uint8))\n",
    "        labels.append(f\"[{lo:.6f}, {hi:.6f}]\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10), constrained_layout=True)\n",
    "    ax00, ax01 = axes[0]\n",
    "    ax10, ax11 = axes[1]\n",
    "\n",
    "    if prph_binary:\n",
    "        eps = (np.finfo(prph.dtype).eps if prph_eps is None else float(prph_eps))\n",
    "        prph_disp = (prph > eps).astype(np.uint8)\n",
    "        ax00.imshow(prph_disp, cmap=\"gray\", vmin=0, vmax=1, interpolation=\"nearest\", origin=origin)\n",
    "        title_left = \"Peripherin (binary)\"\n",
    "    else:\n",
    "        vmax = float(np.percentile(prph, 99.5))\n",
    "        ax00.imshow(prph, cmap=\"gray\", vmin=0, vmax=vmax, origin=origin)\n",
    "        title_left = \"Peripherin (raw)\"\n",
    "    ax00.set_title(f\"{title_left}\" if case_id else title_left)\n",
    "    ax00.axis(\"off\")\n",
    "\n",
    "    for ax, m, lab in zip([ax01, ax10, ax11], masks, labels):\n",
    "        ax.imshow(m, vmin=0, vmax=1, interpolation=\"nearest\", origin=origin)\n",
    "        ax.set_title(f\"Prediction ∈ {lab}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "case_id, prph, logits = chosen\n",
    "plot_prph_and_predictions_grid(prph, logits, thresholds=[0.9999, 0.99999, 0.999999], case_id=case_id, prph_binary=False, prph_eps=1)\n",
    "plot_prph_and_predictions_grid(prph, logits, thresholds=[0.9999, 0.99999, 0.999999], case_id=case_id, prph_binary=True, prph_eps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da03a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crop_pair(prph, logits, *, crop=None, center_size=None):\n",
    "    \"\"\"\n",
    "    Crop PRPH and logits identically.\n",
    "\n",
    "    Use ONE of:\n",
    "      - crop=(y0, y1, x0, x1)         # half-open box [y0:y1, x0:x1]\n",
    "      - center_size=(cy, cx, h, w)    # center coords + box size\n",
    "\n",
    "    Returns:\n",
    "      prph_c, logits_c  (cropped arrays)\n",
    "    \"\"\"\n",
    "    assert (crop is None) ^ (center_size is None), \"Provide crop OR center_size (not both).\"\n",
    "    H, W = prph.shape\n",
    "    assert logits.shape == prph.shape, \"prph/logits shape mismatch.\"\n",
    "\n",
    "    if crop is not None:\n",
    "        y0, y1, x0, x1 = map(int, crop)\n",
    "    else:\n",
    "        cy, cx, h, w = map(int, center_size)\n",
    "        y0 = cy - h // 2\n",
    "        y1 = y0 + h\n",
    "        x0 = cx - w // 2\n",
    "        x1 = x0 + w\n",
    "\n",
    "    \n",
    "    y0 = max(0, min(y0, H - 1))\n",
    "    y1 = max(y0 + 1, min(y1, H))\n",
    "    x0 = max(0, min(x0, W - 1))\n",
    "    x1 = max(x0 + 1, min(x1, W))\n",
    "\n",
    "    return prph[y0:y1, x0:x1], logits[y0:y1, x0:x1]\n",
    "\n",
    "\n",
    "prph_c, logits_c = crop_pair(prph, logits, crop=(600, 800, 150, 350))\n",
    "plot_prph_and_predictions_grid(prph_c, logits_c, thresholds=[0.3, 0.99999, 0.999999], case_id=\"CASE123\", prph_binary=False, prph_eps=1)\n",
    "plot_prph_and_predictions_grid(prph_c, logits_c, thresholds=[0.9999, 0.99999, 0.999999], case_id=\"CASE123\", prph_binary=True, prph_eps=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
